services:

  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - 2181:2181
    networks:
      - etl_network
    
  # Kafka broker
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
      - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CREATE_TOPICS: "etl:1:1"
    networks:
      - etl_network

  # Kafka connect sink
  connect:
    image: confluentinc/cp-kafka-connect:latest
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_PLUGIN_PATH: /usr/share/java,/etc/kafka-connect/plugins
      CLICKHOUSE_PASSWORD: ${CH_ADMIN_PWD}
      CLICKHOUSE_USER: ${CH_ADMIN_USER}
    volumes:
      - ./connector/plugins:/etc/kafka-connect/plugins
      - ./connector/config:/etc/kafka-connect/config
    depends_on:
      - kafka
      - zookeeper
    networks:
      - etl_network

  # Kafka ClickHouse connector setup  
  connect-setup:
    build:
      context: ./connector/setup/
      dockerfile: Dockerfile
    environment:
      CLICKHOUSE_PASSWORD: ${CH_ADMIN_PWD}
      CLICKHOUSE_USER: ${CH_ADMIN_USER}
    network_mode: "host"

  # ClickHouse OLAP DB
  clickhouse:
    image: docker.io/bitnami/clickhouse:24
    environment:
      - CLICKHOUSE_ADMIN_USER=${CH_ADMIN_USER}
      - CLICKHOUSE_ADMIN_PASSWORD=${CH_ADMIN_PWD}
    ports:
      - '8123:8123'
    volumes:
      - clickhouse_data:/bitnami/clickhouse
      - ./clickhouse/init.sh:/docker-entrypoint-initdb.d/init.sh
    networks:
      - etl_network

  # --------------------------------- Airflow ---------------------------------
  # Airflow worker
  airflow-worker:
    image: bitnami/airflow:latest
    environment:
      - AIRFLOW_COMPONENT_TYPE=worker
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=${PG_ADMIN_USER}
      - AIRFLOW_DATABASE_PASSWORD=${PG_ADMIN_PWD}
      - AIRFLOW_WEBSERVER_HOST=airflow
      - AIRFLOW_WEBSERVER_PORT_NUMBER=8090
      - AIRFLOW_FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
      - AIRFLOW_SECRET_KEY=a25mQ1FHTUh3MnFRSk5KMEIyVVU2YmN0VGRyYTVXY08=
    volumes:
      - ./Airflow/covid_etl/requirements.txt:/bitnami/python/requirements.txt
      - ./Airflow/covid_etl:/opt/bitnami/airflow/dags/covid_etl
    networks:
      - etl_network

  # Airflow scheduler
  airflow-scheduler:
    image: bitnami/airflow:latest
    environment:
      - AIRFLOW_COMPONENT_TYPE=scheduler
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=${PG_ADMIN_USER}
      - AIRFLOW_DATABASE_PASSWORD=${PG_ADMIN_PWD}
      - AIRFLOW_WEBSERVER_HOST=airflow
      - AIRFLOW_WEBSERVER_PORT_NUMBER=8090
      - AIRFLOW_FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
      - AIRFLOW_SECRET_KEY=a25mQ1FHTUh3MnFRSk5KMEIyVVU2YmN0VGRyYTVXY08=
    volumes:
      - ./Airflow/covid_etl/requirements.txt:/bitnami/python/requirements.txt
      - ./Airflow/covid_etl:/opt/bitnami/airflow/dags/covid_etl
    networks:
      - etl_network

  # Airflow webserver
  airflow:
    image: bitnami/airflow:latest
    ports:
      - '8090:8090'
    environment:
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=${PG_ADMIN_USER}
      - AIRFLOW_DATABASE_PASSWORD=${PG_ADMIN_PWD}
      - AIRFLOW_PASSWORD=${AF_PWD}
      - AIRFLOW_USERNAME=${AF_USER}
      - AIRFLOW_WEBSERVER_PORT_NUMBER=8090
      - AIRFLOW_FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
      - AIRFLOW_SECRET_KEY=a25mQ1FHTUh3MnFRSk5KMEIyVVU2YmN0VGRyYTVXY08=
    volumes:
      - ./Airflow/covid_etl/requirements.txt:/bitnami/python/requirements.txt
      - ./Airflow/covid_etl:/opt/bitnami/airflow/dags/covid_etl
    networks:
      - etl_network

  # Databases for Airflow and users
  postgresql:
    image: docker.io/bitnami/postgresql:latest
    ports:
      - 5432:5432
    volumes:
      - 'postgresql_data:/bitnami/postgresql'
    environment:
      - POSTGRESQL_DATABASE=bitnami_airflow
      - POSTGRESQL_USERNAME=${PG_ADMIN_USER}
      - POSTGRESQL_PASSWORD=${PG_ADMIN_PWD}
    networks:
      - etl_network

  redis:
    image: docker.io/bitnami/redis:latest
    volumes:
      - 'redis_data:/bitnami'
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    networks:
      - etl_network

  # Kafka UI
  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 8080:8080
    environment:
      DYNAMIC_CONFIG_ENABLED: 'true'
    volumes:
      - ./UI//kui/config.yml:/etc/kafkaui/dynamic_config.yaml
    networks:
      - etl_network
    depends_on:
      - kafka

  # RestAPI
  rest-api:
    build:
      context: ./rest/
      dockerfile: Dockerfile
    ports:
      - 8000:8000
    environment:
      - CH_HOST=clickhouse
      - CH_ADMIN_USER=${CH_ADMIN_USER}
      - CH_ADMIN_PWD=${CH_ADMIN_PWD}
      - PG_HOST=postgresql
      - PG_ADMIN_USER=${PG_ADMIN_USER}
      - PG_ADMIN_PWD=${PG_ADMIN_PWD}
    networks:
      - etl_network
    depends_on:
      - clickhouse
      - postgresql

volumes:
  clickhouse_data:
    driver: local
  postgresql_data:
    driver: local
  redis_data:
    driver: local


networks:
  etl_network:
    driver: bridge
